<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><link rel="stylesheet" href="stylesheet.css" /><title>080_Formal_Grammars</title></head><body><div><span id="page1"></span><p class="p_style0"><span class="style0">CS143</span></p><p class="p_style1"><span class="style0">Handout 08</span></p><p class="p_style0"><span class="style0">Summer 2011</span></p><p class="p_style2"><span class="style0">June 24</span><span class="style1">th</span><span class="style0">, 2011</span></p><p class="p_style3"><span class="style2">Formal Grammars</span></p><p class="p_style2"><span class="style0">Handout written by Maggie Johnson and Julie Zelenski.</span></p><p class="p_style0"><span class="style3">What is a grammar?</span></p><p class="p_style4"><span class="style4">A</span><span class="style4"> </span><span class="style5"> grammar</span><span class="style5"> </span><span class="style4"> is a powerful tool for describing and analyzing languages. It is a set of rules by which valid sentences in a language are constructed. Here’s a trivial example of English grammar:</span></p><table class="borderless"><colgroup><col style="width:99px;" /><col style="width:35px;" /><col style="width:277px;" /></colgroup><tr><td><p class="p_style5"><span class="style6">sentence</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style6">&lt;subject&gt; &lt;verb-phrase&gt; &lt;object&gt;</span></p></td></tr><tr><td><p class="p_style5"><span class="style6">subject</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">This | Computers | I</span></p></td></tr><tr><td><p class="p_style5"><span class="style6">verb-phrase</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style6">&lt;adverb&gt; &lt;verb&gt;</span><span class="style6"> </span><span class="style7"> |</span><span class="style7"> </span><span class="style6"> &lt;verb&gt;</span></p></td></tr><tr><td><p class="p_style5"><span class="style6">adverb</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">never</span></p></td></tr><tr><td><p class="p_style5"><span class="style6">verb</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">is | run | am | tell</span></p></td></tr><tr><td><p class="p_style5"><span class="style6">object</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">the</span><span class="style7"> </span><span class="style6"> &lt;noun&gt;</span><span class="style6"> </span><span class="style7"> |a</span><span class="style7"> </span><span class="style6"> &lt;noun&gt;</span><span class="style6"> </span><span class="style7"> |</span><span class="style7"> </span><span class="style6"> &lt;noun&gt;</span></p></td></tr><tr><td><p class="p_style5"><span class="style6">noun</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">university | world | cheese | lies</span></p></td></tr></table><p class="p_style4"><span class="style4">Using the above rules or</span><span class="style4"> </span><span class="style5"> productions</span><span class="style4">, we can derive simple sentences such as these:</span></p><p class="p_style6"><span class="style7">This is a university.</span></p><p class="p_style6"><span class="style7">Computers run the world.</span></p><p class="p_style6"><span class="style7">I am the cheese.</span></p><p class="p_style6"><span class="style7">I never tell lies.</span></p><p class="p_style4"><span class="style4">Here is a</span><span class="style4"> </span><span class="style5"> leftmost derivation</span><span class="style5"> </span><span class="style4"> of the first sentence using these productions.</span></p><p class="p_style7"><span class="style6">sentence</span></p><p class="p_style8"><span class="style7">–&gt; –&gt; –&gt; –&gt; –&gt; –&gt;</span></p><p class="p_style7"><span class="style6">&lt;subject&gt; &lt;verb-phrase&gt; &lt;object&gt;</span><span class="style6"> </span><span class="style7"> This</span><span class="style7"> </span><span class="style6"> &lt;verb-phrase&gt; &lt;object&gt;</span></p><p class="p_style7"><span class="style7">This</span><span class="style7"> </span><span class="style6"> &lt;verb&gt; &lt;object&gt;</span></p><p class="p_style7"><span class="style7">This is</span><span class="style7"> </span><span class="style6"> &lt;object&gt;</span></p><p class="p_style9"><span class="style7">This is a</span><span class="style7"> </span><span class="style6"> &lt;noun&gt; </span><br /><span class="style6"> </span><span class="style7">This is a university</span></p><p class="p_style10"><span class="style4">In addition to several reasonable sentences, we can also derive nonsense like "Computers run cheese" and "This am a lies". These sentences don't make semantic sense, but they are syntactically correct because they are of the sequence of subject, verb­phrase, and object. Formal grammars are a tool for</span><span class="style4"> </span><span class="style5"> syntax</span><span class="style4">, not</span><span class="style4"> </span><span class="style5"> semantics</span><span class="style4">. We worry about semantics at a later point in the compiling process. In the syntax analysis phase, we verify structure, not meaning.</span></p><span id="page2"></span><p class="p_style0"><span class="style3">Vocabulary</span></p><p class="p_style0"><span class="style4">We need to review some definitions before we can proceed:</span></p><table class="borderless"><colgroup><col style="width:81px;" /><col style="width:15px;" /><col style="width:523px;" /></colgroup><tr><td><p class="p_style5"><span class="style5">grammar</span></p></td><td rowspan="10"></td><td><p class="p_style5"><span class="style4">a set of rules by which valid sentences in a language are constructed.</span></p></td></tr><tr><td><p class="p_style5"><span class="style5">nonterminal</span></p></td><td><p class="p_style5"><span class="style4">a grammar symbol that can be replaced/expanded to a sequence of symbols.</span></p></td></tr><tr><td><p class="p_style5"><span class="style5">terminal</span></p></td><td><p class="p_style5"><span class="style4">an actual word in a language; these are the symbols in a grammar that cannot be replaced by anything else. "terminal" is supposed to conjure up the idea that it is a dead­end—no further expansion is possible.</span></p></td></tr><tr><td><p class="p_style5"><span class="style5">production</span></p></td><td><p class="p_style5"><span class="style4">a grammar rule that describes how to replace/exchange symbols. The general form of a production for a nonterminal is:</span></p></td></tr><tr><td rowspan="2"></td><td><p class="p_style5"><span class="style7">X –&gt;Y</span><span class="style8">1</span><span class="style7">Y</span><span class="style8">2</span><span class="style7">Y</span><span class="style8">3</span><span class="style7">...Y</span><span class="style8">n</span></p></td></tr><tr><td><p class="p_style5"><span class="style4">The nonterminal</span><span class="style4"> </span><span class="style7"> X</span><span class="style7"> </span><span class="style4"> is declared equivalent to the concatenation of the symbols</span><span class="style4"> </span><span class="style7"> Y</span><span class="style9">1</span><span class="style7">Y</span><span class="style9">2</span><span class="style7">Y</span><span class="style9">3</span><span class="style7">...Y</span><span class="style9">n</span><span class="style4">. The production means that anywhere where we encounter</span><span class="style4"> </span><span class="style7"> X</span><span class="style4">, we may replace it by the string</span><span class="style4"> </span><span class="style7"> Y</span><span class="style9">1</span><span class="style7">Y</span><span class="style9">2</span><span class="style7">Y</span><span class="style9">3</span><span class="style7">...Y</span><span class="style9">n</span><span class="style10">.</span><span class="style10"> </span><span class="style4"> Eventually we will have a string containing nothing that can be expanded further, i.e., it will consist of only terminals. Such a string is called a</span><span class="style4"> </span><span class="style5"> sentence</span><span class="style4">. In the context of programming languages, a sentence is a syntactically correct and complete program.</span></p></td></tr><tr><td><p class="p_style5"><span class="style5">derivation</span></p></td><td><p class="p_style5"><span class="style4">a sequence of applications of the rules of a grammar that produces a finished string of terminals. A</span><span class="style4"> </span><span class="style5"> leftmost derivation</span><span class="style5"> </span><span class="style4"> is where we always substitute for the leftmost nonterminal as we apply the rules (we can similarly define a rightmost derivation). A derivation is also called a</span><span class="style4"> </span><span class="style5"> parse</span><span class="style4">.</span></p></td></tr><tr><td><p class="p_style5"><span class="style5">start symbol</span></p></td><td><p class="p_style5"><span class="style4">a grammar has a single nonterminal (the start symbol) from which all sentences derive:</span></p></td></tr><tr><td rowspan="2"></td><td><p class="p_style5"><span class="style7">S –&gt; X</span><span class="style8">1</span><span class="style7">X</span><span class="style8">2</span><span class="style7">X</span><span class="style8">3</span><span class="style7">...X</span><span class="style8">n</span></p></td></tr><tr><td><p class="p_style5"><span class="style4">All sentences are derived from</span><span class="style4"> </span><span class="style7"> S</span><span class="style7"> </span><span class="style4"> by successive replacement using the productions of the grammar.</span></p></td></tr><tr><td><p class="p_style5"><span class="style5">null symbol</span></p></td><td><p class="p_style5"><span class="style11">e</span></p></td><td><p class="p_style5"><span class="style4">it is sometimes useful to specify that a symbol can be replaced by nothing at all. To indicate this, we use the null symbol</span><span class="style4"> </span><span class="style12"> e</span><span class="style12"> </span><span class="style4"> , e.g.,</span><span class="style4"> </span><span class="style7"> A –&gt; B |</span><span class="style7"> </span><span class="style12"> e</span><span class="style4">.</span></p></td></tr><tr><td><p class="p_style5"><span class="style5">BNF</span></p></td><td></td><td><p class="p_style5"><span class="style4">a way of specifying programming languages using formal grammars and production rules with a particular form of notation (Backus­Naur form).</span></p></td></tr></table><span id="page3"></span><p class="p_style0"><span class="style4">A few grammar exercises to try on your own (The alphabet in each case is</span><span class="style4"> </span><span class="style7"> {a,b}.)</span></p><ul><li><p class="p_style11"><span class="style13">o</span><span class="style13"> </span><span class="style4"> Define a grammar for the language of strings with one or more a's followed by zero or more b's.</span></p></li><li><p class="p_style11"><span class="style13">o</span><span class="style13"> </span><span class="style4"> Define a grammar for even­length palindromes.</span></p></li><li><p class="p_style11"><span class="style13">o</span><span class="style13"> </span><span class="style4"> Define a grammar for strings where the number of a's is equal to the number b's.</span></p></li><li><p class="p_style11"><span class="style13">o</span><span class="style13"> </span><span class="style4"> Define a grammar where the number of a's is not equal to the number b's. (Hint: think about it as two separate cases...)</span></p></li></ul><p class="p_style12"><span class="style4">(Can you write regular expressions for these languages? Why or why not?)</span></p><p class="p_style12"><span class="style3">Parse Representation</span></p><p class="p_style13"><span class="style4">In working with grammars, we can represent the application of the rules to derive a sentence in two ways. The first is a derivation as shown earlier for "This is a university" where the rules are applied step­by­step and we substitute for one nonterminal at a time. Think of a derivation as a history of how the sentence was parsed because it not only includes which productions were applied, but also the order they were applied (i.e., which nonterminal was chosen for expansion at each step). There can many different derivations for the same sentence (the leftmost, the rightmost, and so on).</span></p><p class="p_style12"><span class="style4">A</span><span class="style4"> </span><span class="style5"> parse tree</span><span class="style5"> </span><span class="style4"> is the second method for representation. It diagrams how each symbol derives from other symbols in a hierarchical manner. Here is a parse tree for "This is a</span> <span class="style4">university":</span></p><p class="p_style12"><span class="style14">s</span> <span class="style14">subject</span> <span class="style14">v-p</span></p><p class="p_style12"><span class="style14">object</span> <span class="style14">This</span></p><p class="p_style12"><span class="style14">verb</span> <span class="style14">a</span> <span class="style14">noun</span> <span class="style14">is</span></p><p class="p_style12"><span class="style14">university</span></p><p class="p_style14"><span class="style4">Although the parse tree includes all of the productions that were applied, it does not encode the order they were applied. For an unambiguous grammar (we’ll define ambiguity in a minute), there is exactly one parse tree for a particular sentence.</span></p><p class="p_style14"><span class="style3">More Definitions</span></p><p class="p_style15"><span class="style4">Here are some other definitions we will need, described in reference to this example grammar:</span></p><table class="borderless"><colgroup><col style="width:19px;" /><col style="width:37px;" /><col style="width:46px;" /></colgroup><tr><td><p class="p_style5"><span class="style7">S</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">AB</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">A</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">Ax | y</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">B</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">z</span></p></td></tr></table><span id="page4"></span><p class="p_style0"><span class="style5">alphabet</span></p><p class="p_style16"><span class="style4">The alphabet is</span><span class="style4"> </span><span class="style7"> {S, A, B, x, y, z}.</span><span class="style7"> </span><span class="style4"> It is divided into two disjoint sets. The</span><span class="style4"> </span><span class="style5"> terminal alphabet</span><span class="style5"> </span><span class="style4"> consists of terminals, which appear in the sentences of the language:</span><span class="style4"> </span><span class="style7"> {x, y, z}</span><span class="style4">. The remaining symbols are the</span><span class="style4"> </span><span class="style5"> nonterminal alphabet</span><span class="style4">; these are the symbols that appear on the left side of productions and can be replaced during the course of a derivation:</span><span class="style4"> </span><span class="style7"> {S, A, B}.</span><span class="style7"> </span><span class="style4"> Formally, we use</span><span class="style4"> </span><span class="style3"> V</span><span class="style3"> </span><span class="style4"> for the alphabet,</span><span class="style4"> </span><span class="style3"> T</span><span class="style3"> </span><span class="style4"> for the terminal alphabet and</span><span class="style4"> </span><span class="style3"> N</span><span class="style3"> </span><span class="style4"> for the nonterminal alphabet giving us:</span><span class="style4"> </span><span class="style3"> V</span><span class="style3"> </span><span class="style4"> =</span><span class="style4"> </span><span class="style3"> T</span><span class="style3"> </span><span class="style12"> ¨</span><span class="style12"> </span><span class="style3"> N</span><span class="style4">, and</span><span class="style4"> </span><span class="style3"> T</span><span class="style3"> </span><span class="style12"> ˙</span><span class="style12"> </span><span class="style3"> N</span><span class="style3"> </span><span class="style4"> =</span><span class="style4"> </span><span class="style12"> ˘</span><span class="style12"> </span><span class="style4"> .</span></p><p class="p_style17"><span class="style4">The convention used in our lecture notes are a sans­serif font for grammar elements, lowercase for terminals, uppercase for nonterminals, and underlined lowercase (e.g.,</span><span class="style4"> </span><span class="style15"> u</span><span class="style7">,</span><span class="style7"> </span><span class="style15"> v</span><span class="style4">) to denote arbitrary strings of terminal and nonterminal symbols (possibly null). In some textbooks, Greek letters are used for arbitrary strings of terminal and nonterminal symbols (e.g.,</span><span class="style4"> </span><span class="style12"> a, b</span><span class="style12"> </span><span class="style4"> )</span></p><p class="p_style15"><span class="style5">context­free grammar</span></p><p class="p_style18"><span class="style4">To define a language, we need a set of productions, of the general form:</span><span class="style4"> </span><span class="style15"> u</span><span class="style7"> </span><span class="style7"> –&gt;</span><span class="style7"> </span><span class="style15"> v</span><span class="style4">. In a</span><span class="style4"> </span><span class="style5"> context­free grammar</span><span class="style4">,</span><span class="style4"> </span><span class="style15"> u</span><span class="style7"> </span><span class="style4"> is a single nonterminal and</span><span class="style4"> </span><span class="style15"> v</span><span class="style7"> </span><span class="style4"> is an arbitrary string of terminal and nonterminal symbols. When parsing, we can replace</span><span class="style4"> </span><span class="style15"> u</span><span class="style7"> </span><span class="style4"> by</span><span class="style4"> </span><span class="style15"> v</span><span class="style7"> </span><span class="style4"> wherever it occurs. We shall refer to this set of productions symbolically as</span><span class="style4"> </span><span class="style3"> P.</span></p><p class="p_style19"><span class="style5">formal grammar</span></p><p class="p_style20"><span class="style4">We formally define a grammar as a 4­tuple {</span><span class="style7">S,</span><span class="style7"> </span><span class="style3"> P, N, T</span><span class="style4">}.</span><span class="style4"> </span><span class="style7"> S</span><span class="style7"> </span><span class="style4"> is the start symbol (with</span><span class="style4"> </span><span class="style7"> S</span><span class="style7"> </span><span class="style16"> ˛</span><span class="style16"> </span><span class="style3"> N</span><span class="style4">),</span><span class="style4"> </span><span class="style3"> P</span><span class="style3"> </span><span class="style4"> is the set of productions, and</span><span class="style4"> </span><span class="style3"> N</span><span class="style3"> </span><span class="style4"> and</span><span class="style4"> </span><span class="style3"> T</span><span class="style3"> </span><span class="style4"> are the nonterminal and terminal alphabets. A sentence is a string of symbols in</span><span class="style4"> </span><span class="style3"> T</span><span class="style3"> </span><span class="style4"> derived from</span><span class="style4"> </span><span class="style7"> S</span><span class="style7"> </span><span class="style4"> using one or more applications of productions in</span><span class="style4"> </span><span class="style3"> P.</span><span class="style3"> </span><span class="style4"> A string of symbols derived from</span><span class="style4"> </span><span class="style7"> S</span><span class="style7"> </span><span class="style4"> but possibly including nonterminals is called a</span><span class="style4"> </span><span class="style5"> sentential form</span><span class="style5"> </span><span class="style4"> or a</span><span class="style4"> </span><span class="style5"> working string</span><span class="style4">.</span></p><p class="p_style21"><span class="style4">A production</span><span class="style4"> </span><span class="style15"> u</span><span class="style7"> </span><span class="style7"> –&gt;</span><span class="style7"> </span><span class="style15"> v</span><span class="style7"> </span><span class="style4"> is used to replace an occurrence of</span><span class="style4"> </span><span class="style15"> u</span><span class="style7"> </span><span class="style4"> by</span><span class="style4"> </span><span class="style15"> v</span><span class="style4">. Formally, if we apply a production p</span><span class="style4"> </span><span class="style16"> ˛</span><span class="style16"> </span><span class="style3"> P</span><span class="style3"> </span><span class="style4"> to a string of symbols</span><span class="style4"> </span><span class="style15"> w</span><span class="style7"> </span><span class="style4"> in</span><span class="style4"> </span><span class="style3"> V</span><span class="style3"> </span><span class="style4"> to yield a new string of symbols</span><span class="style4"> </span><span class="style15"> z</span><span class="style7"> </span><span class="style4"> in</span><span class="style4"> </span><span class="style3"> V</span><span class="style4">, we say that</span><span class="style4"> </span><span class="style15"> z</span><span class="style7"> </span><span class="style4"> derived from</span><span class="style4"> </span><span class="style15"> w</span><span class="style7"> </span><span class="style4"> using p, written as follows:</span><span class="style4"> </span><span class="style15"> w</span><span class="style7"> </span><span class="style4"> =&gt;</span><span class="style17">p</span><span class="style17"> </span><span class="style15"> z</span><span class="style4">. We also use:</span></p><ul><li><p class="p_style22"><span class="style15">w</span><span class="style7"> </span><span class="style4"> =&gt;</span><span class="style4"> </span><span class="style15"> z</span></p><ul><li><p class="p_style22"><span class="style15">z</span><span class="style7"> </span><span class="style4"> derives from</span><span class="style4"> </span><span class="style15"> w</span><span class="style7"> </span><span class="style4"> (production unspecified)</span></p></li></ul></li><li><p class="p_style22"><span class="style15">w</span><span class="style7"> </span><span class="style4"> =&gt;</span><span class="style0">*</span><span class="style0"> </span><span class="style15"> z</span></p><ul><li><p class="p_style22"><span class="style15">z</span><span class="style7"> </span><span class="style4"> derives from</span><span class="style4"> </span><span class="style15"> w</span><span class="style7"> </span><span class="style4"> using zero or more productions</span></p></li></ul></li><li><p class="p_style22"><span class="style15">w</span><span class="style7"> </span><span class="style4"> =&gt;</span><span class="style0">+</span><span class="style0"> </span><span class="style15"> z</span></p></li></ul><ul><li><p class="p_style22"><span class="style15">z</span><span class="style7"> </span><span class="style4"> derives from</span><span class="style4"> </span><span class="style15"> w</span><span class="style7"> </span><span class="style4"> using one or more productions</span></p></li></ul><p class="p_style22"><span class="style5">equivalence</span></p><p class="p_style23"><span class="style4">The language L(G) defined by grammar G is the set of sentences derivable using G. Two grammars G and G' are said to be</span><span class="style4"> </span><span class="style5"> equivalent</span><span class="style5"> </span><span class="style4"> if the languages they generate, L(G) and L(G'), are the same.</span></p><span id="page5"></span><p class="p_style0"><span class="style3">Grammar Hiearchy</span></p><p class="p_style24"><span class="style4">We owe a lot of our understanding of grammars to the work of the American linguist Noam Chomsky (yes, the Noam Chomsky known for his politics). There are four categories of formal grammars in the</span><span class="style4"> </span><span class="style5"> Chomsky Hierarchy</span><span class="style4">, they span from Type 0, the most general, to Type 3, the most restrictive. More restrictions on the grammar make it easier to describe and efficiently parse, but reduce the expressive power.</span></p><p class="p_style25"><span class="style4">Type 0: free or unrestricted grammars</span></p><p class="p_style26"><span class="style4">These are the most general. Productions are of the form</span><span class="style4"> </span><span class="style15"> u</span><span class="style7"> </span><span class="style7"> –&gt;</span><span class="style7"> </span><span class="style15"> v</span><span class="style7"> </span><span class="style4"> where both</span><span class="style4"> </span><span class="style15"> u</span><span class="style7"> </span><span class="style4"> and</span><span class="style4"> </span><span class="style15"> v</span><span class="style7"> </span><span class="style4"> are arbitrary strings of symbols in</span><span class="style4"> </span><span class="style3"> V</span><span class="style4">, with</span><span class="style4"> </span><span class="style15"> u</span><span class="style7"> </span><span class="style4"> non­null. There are no restrictions on what appears on the left or right­hand side other than the left­hand side must be non­empty.</span></p><p class="p_style27"><span class="style4">Type 1: context­sensitive grammars</span></p><p class="p_style28"><span class="style4">Productions are of the form</span><span class="style4"> </span><span class="style15"> u</span><span class="style7">X</span><span class="style15">w</span><span class="style7"> </span><span class="style7"> –&gt;</span><span class="style7"> </span><span class="style15"> uvw</span><span class="style7"> </span><span class="style4"> where</span><span class="style4"> </span><span class="style15"> u</span><span class="style4">,</span><span class="style4"> </span><span class="style15"> v</span><span class="style7"> </span><span class="style4"> and</span><span class="style4"> </span><span class="style15"> w</span><span class="style7"> </span><span class="style4"> are arbitrary strings of symbols in</span><span class="style4"> </span><span class="style3"> V</span><span class="style4">, with</span><span class="style4"> </span><span class="style15"> v</span><span class="style7"> </span><span class="style4"> non­null, and</span><span class="style4"> </span><span class="style7"> X</span><span class="style7"> </span><span class="style4"> a single nonterminal. In other words,</span><span class="style4"> </span><span class="style7"> X</span><span class="style7"> </span><span class="style4"> may be replaced by</span><span class="style4"> </span><span class="style15"> v</span><span class="style7"> </span><span class="style4"> but only when it is surrounded by</span><span class="style4"> </span><span class="style15"> u</span><span class="style7"> </span><span class="style4"> and</span><span class="style4"> </span><span class="style15"> w</span><span class="style4">. (i.e., in a particular context).</span></p><p class="p_style29"><span class="style4">Type 2: context­free grammars</span></p><p class="p_style30"><span class="style4">Productions are of the form</span><span class="style4"> </span><span class="style7"> X–&gt;</span><span class="style7"> </span><span class="style15"> v</span><span class="style7"> </span><span class="style4"> where</span><span class="style4"> </span><span class="style15"> v</span><span class="style7"> </span><span class="style4"> is an arbitrary string of symbols in</span><span class="style4"> </span><span class="style3"> V</span><span class="style4">, and</span><span class="style4"> </span><span class="style7"> X</span><span class="style7"> </span><span class="style4"> is a single nonterminal. Wherever you find</span><span class="style4"> </span><span class="style7"> X,</span><span class="style7"> </span><span class="style4"> you can replace with</span><span class="style4"> </span><span class="style15"> v</span><span class="style7"> </span><span class="style4"> (regardless of context).</span></p><p class="p_style31"><span class="style4">Type 3: regular grammars</span></p><p class="p_style32"><span class="style4">Productions are of the form</span><span class="style4"> </span><span class="style7"> X–&gt; a, X–&gt; aY, or X–&gt;</span><span class="style12">e</span><span class="style12"> </span><span class="style4"> where</span><span class="style4"> </span><span class="style7"> X</span><span class="style7"> </span><span class="style4"> and</span><span class="style4"> </span><span class="style7"> Y</span><span class="style7"> </span><span class="style4"> are nonterminals and</span><span class="style4"> </span><span class="style7"> a</span><span class="style7"> </span><span class="style4"> is a terminal. That is, the left­hand side must be a single nonterminal and the right­hand side can be either empty, a single terminal by itself or with a single nonterminal. These grammars are the most limited in terms of expressive power.</span></p><p class="p_style14"><span class="style4">Every type 3 grammar is a type 2 grammar, and every type 2 is a type 1 and so on. Type 3 grammars are particularly easy to parse because of the lack of recursive constructs. Efficient parsers exist for many classes of Type 2 grammars. Although Type 1 and Type 0 grammars are more powerful than Type 2 and 3, they are far less useful since we cannot create efficient parsers for them. In designing programming languages using formal grammars, we will use Type 2 or context­free grammars, often just abbreviated as CFG.</span></p><p class="p_style14"><span class="style3">Issues in parsing context­free grammars</span></p><span id="page6"></span><p class="p_style14"><span class="style4">There are several efficient approaches to parsing most Type 2 grammars and we will talk through them over the next few lectures. However, there are some issues that can interfere with parsing that we must take into consideration when designing the</span> <span class="style4">grammar. Let’s take a look at three of them: ambiguity, recursive rules, and left­factoring.</span></p><p class="p_style15"><span class="style3">Ambiguity</span></p><p class="p_style33"><span class="style4">If a grammar permits more than one parse tree for some sentences, it is said to be</span><span class="style4"> </span><span class="style5"> ambiguous</span><span class="style4">. For example, consider the following classic arithmetic expression grammar:</span></p><table class="borderless"><colgroup><col style="width:53px;" /><col style="width:63px;" /><col style="width:121px;" /></colgroup><tr><td><p class="p_style5"><span class="style7">E</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">E op E | ( E ) | int</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">op</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">+| - | * | /</span></p></td></tr></table><p class="p_style14"><span class="style4">This grammar denotes expressions that consist of integers joined by binary operators and possibly including parentheses. As defined above, this grammar is ambiguous because for certain sentences we can construct more than one parse tree. For example, consider the expression</span><span class="style4"> </span><span class="style7"> 10 – 2 * 5</span><span class="style4">. We parse by first applying the production</span><span class="style4"> </span><span class="style7"> E –&gt; E op E.</span><span class="style7"> </span><span class="style4"> The parse tree on the left chooses to expand that first</span><span class="style4"> </span><span class="style7"> op</span><span class="style7"> </span><span class="style4"> to</span><span class="style4"> </span><span class="style7"> *,</span><span class="style7"> </span><span class="style4"> the one on the right to</span><span class="style4"> </span><span class="style7"> -.</span><span class="style7"> </span><span class="style4"> We have two completely different parse trees. Which one is correct?</span></p><p class="p_style34"><span class="style14">E</span></p><p class="p_style35"><span class="style14">E op *</span></p><p class="p_style14"><span class="style14">E</span> <span class="style14">E </span><br /><img src="images/0.png" width="2" /><span class="style14">int 10</span></p><p class="p_style36"><span class="style14">op -</span> <span class="style14">E</span> <span class="style14">int 2</span></p><p class="p_style37"><span class="style14">E </span><br /><span class="style14">int 5</span></p><p class="p_style38"><span class="style14">E </span><br /><span class="style14">int 10</span></p><p class="p_style39"><span class="style14">op -</span> <span class="style14">E</span> <span class="style14">E </span><br /><span class="style14">int</span></p><p class="p_style40"><span class="style14">op *</span></p><p class="p_style41"><span class="style14">E </span><br /><span class="style14">int</span></p><p class="p_style42"><span class="style14">5 </span><br /><span class="style14">2</span></p><p class="p_style24"><span class="style4">Both trees are legal in the grammar as stated and thus either interpretation is valid. Although natural languages can tolerate some kind of ambiguity (e.g., puns, plays on words, etc.), it is not acceptable in computer languages. We don’t want the compiler just haphazardly deciding which way to interpret our expressions! Given our expectations from algebra concerning precedence, only one of the trees seems right. The right­hand tree fits our expectation that * "binds tighter" and for that result to be computed first then integrated in the outer expression which has a lower precedence operator.</span></p><p class="p_style43"><span class="style4">It’s fairly easy for a grammar to become ambiguous if you are not careful in its construction. Unfortunately, there is no magical technique that can be used to resolve all varieties of ambiguity. It is an undecidable problem to determine whether any grammar is ambiguous, much less to attempt to mechanically remove all ambiguity. However, that doesn't mean in practice that we cannot detect ambiguity or do something about it. For programming language grammars, we usually take pains to construct an unambiguous grammar or introduce additional disambiguating rules to throw away the undesirable parse trees, leaving only one for each sentence.</span></p><span id="page7"></span><p class="p_style15"><span class="style4">Using the above ambiguous expression grammar, one technique would leave the grammar as is, but add disambiguating rules into the parser implementation. We could code into the parser knowledge of precedence and associativity to break the tie and force the parser to build the tree on the right rather than the left. The advantage of this is that the grammar remains simple and less complicated. But as a downside, the syntactic structure of the language is no longer given by the grammar alone.</span></p><p class="p_style44"><span class="style4">Another approach is to change the grammar to only allow the one tree that correctly reflects our intention and eliminate the others. For the expression grammar, we can separate expressions into multiplicative and additive subgroups and force them to be expanded in the desired order.</span></p><table class="borderless"><colgroup><col style="width:62px;" /><col style="width:63px;" /><col style="width:86px;" /></colgroup><tr><td><p class="p_style5"><span class="style7">E</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">E t_op E | T</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">t_op</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">+| -</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">T</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">T f_op T | F</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">f_op</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">* |/</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">F</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">(E) | int</span></p></td></tr></table><p class="p_style13"><span class="style4">Terms are addition/subtraction expressions and factors used for multiplication and division. Since the base case for expression is a term, addition and subtraction will appear higher in the parse tree, and thus receive lower precedence.</span></p><p class="p_style13"><span class="style4">After verifying that the above re­written grammar has only one parse tree for the earlier ambiguous expression, you might thing we were home free, but now consider the expression</span><span class="style4"> </span><span class="style7"> 10 –2 –5.</span><span class="style7"> </span><span class="style4"> The recursion on both sides of the binary operator allows either side to match repetitions. The arithmetic operators usually associate to the left, so by replacing the right­hand side with the base case will force the repetitive matches onto the left side. The final result is:</span></p><table class="borderless"><colgroup><col style="width:62px;" /><col style="width:63px;" /><col style="width:86px;" /></colgroup><tr><td><p class="p_style5"><span class="style7">E</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">E t_op T | T</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">t_op</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">+| -</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">T</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">T f_op F | F</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">f_op</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">* |/</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">F</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">(E) | int</span></p></td></tr></table><p class="p_style43"><span class="style4">Whew! The obvious disadvantage of changing the grammar to remove ambiguity is that it may complicate and obscure the original grammar definitions. There is no mechanical means to change any ambiguous grammar into an unambiguous one (undecidable, remember?) However, most programming languages have only limited issues with ambiguity that can be resolved using ad hoc techniques.</span></p><span id="page8"></span><p class="p_style0"><span class="style3">Recursive productions</span></p><p class="p_style43"><span class="style4">Productions are often defined in terms of themselves. For example a list of variables in a programming language grammar could be specified by this production:</span></p><p class="p_style43"><span class="style7">variable_list</span></p><p class="p_style43"><span class="style7">–&gt;</span> <span class="style7">variable | variable_list , variable</span></p><p class="p_style15"><span class="style4">Such productions are said to be</span><span class="style4"> </span><span class="style5"> recursive</span><span class="style4">. If the recursive nonterminal is at the left of the right­side of the production, e.g.</span><span class="style4"> </span><span class="style7"> A –&gt;</span><span class="style7"> </span><span class="style15"> u</span><span class="style7"> </span><span class="style7"> | A</span><span class="style15">v</span><span class="style4">, we call the production</span><span class="style4"> </span><span class="style5"> left­recursive</span><span class="style4">. Similarly, we can define a</span><span class="style4"> </span><span class="style5"> right­recursive</span><span class="style5"> </span><span class="style4"> production:</span><span class="style4"> </span><span class="style7"> A –&gt;</span><span class="style7"> </span><span class="style15"> u</span><span class="style7"> </span><span class="style7"> |</span><span class="style7"> </span><span class="style15"> v</span><span class="style7">A</span><span class="style4">. Some parsing techniques have trouble with one or the other variants of recursive productions and so sometimes we have to massage the grammar into a different but equivalent form. Left­recursive productions can be especially troublesome in the top­down parsers (and we’ll see why a bit later). Handily, there is a simple technique for rewriting the grammar to move the recursion to the other side. For example, consider this left­recursive rule:</span></p><p class="p_style15"><span class="style7">X</span></p><p class="p_style15"><span class="style7">–&gt;</span> <span class="style7">Xa | Xb | AB | C | DEF</span></p><p class="p_style14"><span class="style4">To convert the rule, we introduce a new nonterminal</span><span class="style4"> </span><span class="style7"> X'</span><span class="style7"> </span><span class="style4"> that we append to the end of all non­left­recursive productions for</span><span class="style4"> </span><span class="style7"> X</span><span class="style4">. The expansion for the new nonterminal is basically the reverse of the original left­recursive rule. The re­written productions are:</span></p><table class="borderless"><colgroup><col style="width:21px;" /><col style="width:32px;" /><col style="width:128px;" /></colgroup><tr><td><p class="p_style5"><span class="style7">X</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">ABX' | CX' | DEFX'</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">X'</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">aX' | bX' |</span><span class="style7"> </span><span class="style16"> e</span></p></td></tr></table><p class="p_style14"><span class="style4">It appears we just exchanged the left­recursive rules for an equivalent right­recursive version. This might seem pointless, but some parsing algorithms prefer or even require only left or right recursion.</span></p><p class="p_style14"><span class="style3">Left­factoring</span></p><p class="p_style14"><span class="style4">The parser usually reads tokens from left to right and it is convenient if, upon reading a token, it can make an immediate decision about which production from the grammar to expand. However, this can be trouble if there are productions that have common first symbol(s) on the right side of the productions. Here is an example we often see in programming language grammars:</span></p><p class="p_style14"><span class="style7">Stmt</span></p><p class="p_style14"><span class="style7">–&gt;</span> <span class="style7">if Cond then Stmt else Stmt</span></p><p class="p_style14"><span class="style7">| if Cond then Stmt |</span> <span class="style7">Other</span></p><p class="p_style14"><span class="style7">| ....</span></p><span id="page9"></span><p class="p_style45"><span class="style4">The common prefix is</span><span class="style4"> </span><span class="style7"> if Cond then Stmt</span><span class="style4">. This causes problems because when a parser encounter an “if”, it does not know which production to use. A useful technique called</span><span class="style4"> </span><span class="style5"> left­factoring</span><span class="style5"> </span><span class="style4"> allows us to restructure the grammar to avoid this situation. We rewrite the productions to defer the decision about which of the options to choose until we have seen enough of the input to make the appropriate choice. We factor out the common</span> <span class="style4">part of the two options into a shared rule that both will use and then add a new rule that picks up where the tokens diverge.</span></p><p class="p_style46"><span class="style7">Stmt OptElse</span></p><p class="p_style46"><span class="style7">–&gt; –&gt;</span> <span class="style7">if Cond then Stmt OptElse</span></p><p class="p_style46"><span class="style7">|</span> <span class="style7">Other</span></p><p class="p_style46"><span class="style7">| …</span></p><p class="p_style46"><span class="style7">else S |</span></p><p class="p_style46"><span class="style16">e</span></p><p class="p_style43"><span class="style4">In the re­written grammar, upon reading an “if” we expand first production and wait until</span><span class="style4"> </span><span class="style7"> if Cond then Stmt</span><span class="style7"> </span><span class="style4"> has been seen to decide whether to expand</span><span class="style4"> </span><span class="style7"> OptElse</span><span class="style7"> </span><span class="style4"> to</span><span class="style4"> </span><span class="style7"> else</span><span class="style7"> </span><span class="style4"> or</span><span class="style4"> </span><span class="style16"> e</span><span class="style7">.</span></p><p class="p_style43"><span class="style3">Hidden left­factors and hidden left recursion</span></p><p class="p_style14"><span class="style4">A grammar may not appear to have left recursion or left factors, yet still have issues that will interfere with parsing. This may be because the issues are hidden and need to be first exposed via substitution.</span></p><p class="p_style14"><span class="style4">For example, consider this grammar:</span></p><table class="borderless"><colgroup><col style="width:19px;" /><col style="width:34px;" /><col style="width:96px;" /></colgroup><tr><td><p class="p_style5"><span class="style7">A</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">da | acB</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">B</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">abB | daA | Af</span></p></td></tr></table><p class="p_style14"><span class="style4">A cursory examination of the grammar may not detect that the first and second productions of B overlap with the third. We substitute the expansions for A into the third production to expose this:</span></p><table class="borderless"><colgroup><col style="width:19px;" /><col style="width:34px;" /><col style="width:146px;" /></colgroup><tr><td><p class="p_style5"><span class="style7">A</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">da | acB</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">B</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">abB | daA | daf | acBf</span></p></td></tr></table><p class="p_style13"><span class="style4">This exchanges the original third production of B for several new productions, one for each of the productions for A. These directly show the overlap, and we can then left­factor:</span></p><table class="borderless"><colgroup><col style="width:20px;" /><col style="width:33px;" /><col style="width:65px;" /></colgroup><tr><td><p class="p_style5"><span class="style7">A</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">da | acB</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">B</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">aM | daN</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">M</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">bB | cBf</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">N</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">A| f</span></p></td></tr></table><p class="p_style13"><span class="style4">Similarly, the following grammar does not appear to have any left­recursion:</span></p><table class="borderless"><colgroup><col style="width:19px;" /><col style="width:34px;" /><col style="width:60px;" /></colgroup><tr><td><p class="p_style5"><span class="style7">S</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">Tu | wx</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">T</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">Sq | vvS</span></p></td></tr></table><p class="p_style13"><span class="style4">Yet after substitution of S into T, the left­recursion comes to light:</span></p><table class="borderless"><colgroup><col style="width:19px;" /><col style="width:34px;" /><col style="width:108px;" /></colgroup><tr><td><p class="p_style5"><span class="style7">S</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">Tu | wx</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">T</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">Tuq | wxq | vvS</span></p></td></tr></table><p class="p_style13"><span class="style4">If we then eliminate left­recursion, we get:</span></p><span id="page10"></span><table class="borderless"><colgroup><col style="width:20px;" /><col style="width:33px;" /><col style="width:93px;" /></colgroup><tr><td><p class="p_style5"><span class="style7">S</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">Tu | wx</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">T</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">wxqT' | vvST'</span></p></td></tr><tr><td><p class="p_style5"><span class="style7">T'</span></p></td><td><p class="p_style5"><span class="style7">–&gt;</span></p></td><td><p class="p_style5"><span class="style7">uqT' |</span><span class="style7"> </span><span class="style16"> e</span></p></td></tr></table><p class="p_style0"><span class="style3">Programming language case study: ALGOL</span></p><p class="p_style14"><span class="style4">Algol is of interest to us because it was the first programming language to be defined using a grammar. It grew out of an international effort in the late 1950’s to create a "universal programming language" that would run on all machines. At that time, FORTRAN and COBOL were the prominent languages, with new languages sprouting up all around. Programmers became increasingly concerned about portability of programs and being able to communicate with one another on programming topics.</span></p><p class="p_style24"><span class="style4">Consequently the ACM and GAMM (Gesellschaft f</span><span class="style18">ü</span><span class="style4">r angewandte Mathematik und Mechanik) decided to come up with a single programming language that all could use on their computers, and in whose terms programs could be communicated between the users of all machines. Their first decision was not to use FORTRAN as their universal language. This may seem surprising to us today, since it was the most commonly used language back then. However, as Alan J. Perlis, one of the original committee members, puts it:</span></p><p class="p_style47"><span class="style4">"Today, FORTRAN is the property of the computing world, but in 1957, it was an IBM creation and closely tied to IBM hardware. For these reasons, FORTRAN was unacceptable as a universal language."</span></p><p class="p_style13"><span class="style4">ALGOL­58 was the first version of the language, followed up very soon after by ALGOL­60, which is the version that had the most impact. As a language, it introduced the following features:</span></p><ul><li><p class="p_style48"><span class="style13">o</span><span class="style13"> </span><span class="style4"> block structure and nested structures</span></p></li><li><p class="p_style48"><span class="style13">o</span><span class="style13"> </span><span class="style4"> strong typing</span></p></li><li><p class="p_style48"><span class="style13">o</span><span class="style13"> </span><span class="style4"> scoping</span></p></li><li><p class="p_style48"><span class="style13">o</span><span class="style13"> </span><span class="style4"> procedures and functions</span></p></li><li><p class="p_style48"><span class="style13">o</span><span class="style13"> </span><span class="style4"> call by value, call by reference</span></p></li><li><p class="p_style48"><span class="style13">o</span><span class="style13"> </span><span class="style4"> side effects (is this good or bad?)</span></p></li><li><p class="p_style48"><span class="style13">o</span><span class="style13"> </span><span class="style4"> recursion</span></p></li></ul><p class="p_style10"><span class="style4">It may seem surprising that recursion was not present in the original FORTRAN or COBOL. You probably know that to implement recursion we need a runtime stack to store the activation records as functions are called. In FORTRAN and COBOL, activation records were created at compile time, not runtime. Thus, only one activation record per subroutine was created. No stack was used. The parameters for the subroutine were copied into the activation record and that data area was used for subroutine processing.</span></p><span id="page11"></span><p class="p_style15"><span class="style4">The ALGOL report was the first time we see BNF to describe a programming language. Both John Backus and Peter Naur were on the ALGOL committees. They derived this description technique from an earlier paper written by Backus. The technique was adopted because they needed a machine­independent method of description. If one looks at the early definitions of FORTRAN, one can see the links to the IBM hardware. With ALGOL, the machine was not relevant. BNF had a huge impact on programming language design and compiler construction. First, it stimulated a large number of studies on the formal structure of programming languages laying the groundwork for a theoretical approach to language design. Second, a formal syntactic description could be used to drive a compiler directly (as we shall see).</span></p><p class="p_style14"><span class="style4">ALGOL had a tremendous impact on programming language design, compiler construction, and language theory, but the language itself was a commercial failure. Partly this was due to design decisions (overly complex features, no IO) along with the politics of the time (popularity of Fortran, lack of support from the all­powerful IBM, resistance to BNF).</span></p><p class="p_style14"><span class="style3">Bibliography</span></p><p class="p_style49"><span class="style19">A. Aho, R. Sethi, J. Ullman, Compilers: Principles, Techniques, and Tools. Reading, MA:</span></p><p class="p_style50"><span class="style19">Addison-Wesley, 1986.</span></p><p class="p_style51"><span class="style19">J. Backus, “The Syntax and Semantics of the Proposed International Algebraic Language of the Zurich ACM-GAMM Conference,” Proceedings of the International Conference on</span></p><p class="p_style52"><span class="style19">Information Processing, 1959, pp. 125-132.</span></p><p class="p_style51"><span class="style19">N. Chomsky, “On Certain Formal Properties of Grammars,” Information and Control, Vol. 2,</span></p><p class="p_style52"><span class="style19">1959, pp. 137-167.</span></p><p class="p_style51"><span class="style19">J.P. Bennett, Introduction to Compiling Techniques. Berkshire, England: McGraw-Hill, 1990.</span></p><p class="p_style51"><span class="style19">D. Cohen, Introduction to Computer Theory. New York: Wiley, 1986.</span></p><p class="p_style51"><span class="style19">J.C. Martin, Introduction to Languages and the Theory of Computation. New York, NY:</span></p><p class="p_style52"><span class="style19">McGraw-Hill, 1991.</span></p><p class="p_style51"><span class="style19">P. Naur, “Programming Languages, Natural Languages, and Mathematics,” Communications</span></p><p class="p_style52"><span class="style19">of the ACM, Vol 18, No. 12, 1975, pp. 676-683.</span></p><p class="p_style51"><span class="style19">J. Sammet, Programming Languages: History and Fundamentals. Englewood-Cliffs, NJ:</span></p><p class="p_style52"><span class="style19">Prentice-Hall, 1969.</span></p><p class="p_style51"><span class="style19">R.L.Wexelblat, History of Programming Languages. London: Academic Press, 1981.</span></p></div></body></html>